{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hitchhiker_snow = os.path.join(\"raw_data\",\"HitchhikersSnow.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eskimos had over two hundred different words for snow, without which their conversation would probably have got very monotonous. So they would distinguish between thin snow and thick snow, light snow and heavy snow, sludgy snow, brittle snow, snow that came in flurries, snow that came in drifts, snow that came in on the bottom of your neighbor’s boots all over your nice clean igloo floor, the snows of winter, the snows of spring, the snows you remember from your childhood that were so much better than any of your modern snow, fine snow, feathery snow, hill snow, valley snow, snow that falls in the morning, snow that falls at night, snow that falls all of a sudden just when you were going out fishing, and snow that despite all your efforts to train them, the huskies have pissed on.\n"
     ]
    }
   ],
   "source": [
    "with open(hitchhiker_snow, 'r') as snowdoc:\n",
    "    snowdoc=snowdoc.read()\n",
    "    print(snowdoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# count instances of sentences\n",
    "sentence_count= snowdoc.count(\".\")+snowdoc.count(\"!\")+snowdoc.count(\"?\")\n",
    "print(sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eskimos', 'had', 'over', 'two', 'hundred', 'different', 'words', 'for', 'snow,', 'without', 'which', 'their', 'conversation', 'would', 'probably', 'have', 'got', 'very', 'monotonous.', 'So', 'they', 'would', 'distinguish', 'between', 'thin', 'snow', 'and', 'thick', 'snow,', 'light', 'snow', 'and', 'heavy', 'snow,', 'sludgy', 'snow,', 'brittle', 'snow,', 'snow', 'that', 'came', 'in', 'flurries,', 'snow', 'that', 'came', 'in', 'drifts,', 'snow', 'that', 'came', 'in', 'on', 'the', 'bottom', 'of', 'your', 'neighbor’s', 'boots', 'all', 'over', 'your', 'nice', 'clean', 'igloo', 'floor,', 'the', 'snows', 'of', 'winter,', 'the', 'snows', 'of', 'spring,', 'the', 'snows', 'you', 'remember', 'from', 'your', 'childhood', 'that', 'were', 'so', 'much', 'better', 'than', 'any', 'of', 'your', 'modern', 'snow,', 'fine', 'snow,', 'feathery', 'snow,', 'hill', 'snow,', 'valley', 'snow,', 'snow', 'that', 'falls', 'in', 'the', 'morning,', 'snow', 'that', 'falls', 'at', 'night,', 'snow', 'that', 'falls', 'all', 'of', 'a', 'sudden', 'just', 'when', 'you', 'were', 'going', 'out', 'fishing,', 'and', 'snow', 'that', 'despite', 'all', 'your', 'efforts', 'to', 'train', 'them,', 'the', 'huskies', 'have', 'pissed', 'on.']\n",
      "140\n",
      "652\n"
     ]
    }
   ],
   "source": [
    "# break up words and remove non-letter characters\n",
    "paragraph= re.split(\" \",snowdoc)\n",
    "print(paragraph)\n",
    "# count number of words\n",
    "word_count= len(paragraph)\n",
    "\n",
    "# count number of letters in all words\n",
    "word_len= 0\n",
    "for word in paragraph:\n",
    "    word_len= word_len + len(word)\n",
    "    \n",
    "print(word_count)\n",
    "print(word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_end= (\"?\",\"!\",\".\")\n",
    "punctuation=(\",\",\"\\\"\",\"\\'\",\"/\",\";\",\"-\",\"&\")\n",
    "word_len= 0\n",
    "word_count= 0\n",
    "sentence_count= 0\n",
    "\n",
    "for character in snowdoc:\n",
    "    if character==\" \" and word_count !=0: # end of word\n",
    "        word_count= wordcount+1\n",
    "\n",
    "    elif character in sentence_end: # end of sentence\n",
    "        sentence_count= sentence_count+1\n",
    "        word_count= wordcount+1\n",
    "\n",
    "    elif character in sentence_end != true:\n",
    "        if character in puncuation:\n",
    "            next\n",
    "        else:\n",
    "            word_len = word_len+1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate Word Count: 140\n",
      "Approximate Sentence Count: 2\n",
      "Average Letter Count: 4.6571428571428575\n",
      "Average Sentence Length: 70.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Approximate Word Count: \"+ str(word_count))\n",
    "print(\"Approximate Sentence Count: \"+ str(sentence_count))\n",
    "print(\"Average Letter Count: \"+ str(word_len/word_count))\n",
    "print(\"Average Sentence Length: \"+ str(word_count/sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hitchhiker_snow.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
